service: aggregate-service

provider:
  name: aws
  region: us-east-1
  stage: ${opt:stage, self:custom.defaultStage}

custom:
  defaultStage: default
  environment: ${file(env.yml):${self:provider.stage}, file(env.yml):default}

resources:
  Resources:
    S3Assets:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: ${self:custom.environment.BUCKET_NAME}
    BlockBatchTable:
      Type: AWS::DynamoDB::Table
      Properties:
        TableName: ${self:custom.environment.AWS_DYNAMODB_BLOCK_BATCH_TABLE_NAME}
        AttributeDefinitions:
          - AttributeName: BatchId
            AttributeType: S
        KeySchema:
          - AttributeName: BatchId
            KeyType: HASH
        ProvisionedThroughput: # Might need to turn on auto-scaling, default to 50 reads and writes for now.
          ReadCapacityUnits: 50
          WriteCapacityUnits: 50
    BlockMetadataTable:
      Type: AWS::DynamoDB::Table
      Properties:
        TableName: ${self:custom.environment.AWS_DYNAMODB_BLOCK_METADATA_TABLE_NAME}
        AttributeDefinitions:
          - AttributeName: BlockHeight
            AttributeType: N
        KeySchema:
          - AttributeName: BlockHeight
            KeyType: HASH
        ProvisionedThroughput: # Might need to turn on auto-scaling, default to 50 reads and writes for now.
          ReadCapacityUnits: 50
          WriteCapacityUnits: 50
    ServiceMetadataTable:
      Type: AWS::DynamoDB::Table
      Properties:
        TableName: ${self:custom.environment.AWS_DYNAMODB_SERVICE_METADATA_TABLE_NAME}
        AttributeDefinitions:
          - AttributeName: Property
            AttributeType: S
        KeySchema:
          - AttributeName: Property
            KeyType: HASH
        ProvisionedThroughput: # Might need to turn on auto-scaling, default to 50 reads and writes for now.
          ReadCapacityUnits: 50
          WriteCapacityUnits: 50


## Below is to run serverless against localstack
#plugins:
#  - serverless-localstack
#
#custom:
#  localstack:
#    stages:
#      - local
